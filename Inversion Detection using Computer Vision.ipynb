{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='Teal'> Inversion Detection</font> <font color='green'>using</font> <font color='red'>Computer Vision</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "from shape_context import ShapeContext\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting an Helper Function for Finding Dilation Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation_constant_selector(image):\n",
    "    ContourCount =[]\n",
    "    kernel_value =0\n",
    "    for i in range (1,100):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (i,i))\n",
    "        dilate = cv2.dilate(image,kernel,iterations=1)\n",
    "        contours = cv2.findContours(dilate,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        ContourCount.append(len(contours[1]))\n",
    "#         plt.plot(ContourCount)\n",
    "#         plt.show()\n",
    "        if i >=4:\n",
    "            pixelC, trigg = findCurveFit(ContourCount)\n",
    "            if trigg == True:\n",
    "                kernel_value=i\n",
    "                break\n",
    "    return kernel_value            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions for Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "\n",
    "    y = (L / (1 + np.exp(k*(x+x0)))+b)\n",
    "    return (y)\n",
    "\n",
    "\n",
    "def isCurveSigmoid(ContourCounts, count):\n",
    "\n",
    "\n",
    "        xIndex = len(ContourCounts)\n",
    "\n",
    "        p0 = [max(ContourCounts), np.median(xIndex),1,min(ContourCounts)] # this is an mandatory initial guess\n",
    "\n",
    "        popt, pcov = curve_fit(sigmoid, list(range(xIndex)), ContourCounts, p0, method='lm', maxfev=10000)\n",
    "\n",
    "        yVals = sigmoid(list(range(xIndex)), *popt)\n",
    "\n",
    "    \n",
    "\n",
    "        # May have to check for a value much less than Median to avoid false positives.\n",
    "        if np.median(yVals[:3]) - np.median(yVals[-3:]) > 15:\n",
    "            print('Triggered Event')\n",
    "            return True\n",
    "        else:\n",
    "\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def findCurveFit(ContourCount):\n",
    "\n",
    "    triggerEvent = False\n",
    "\n",
    "    if isCurveSigmoid(ContourCount, len(ContourCount)):\n",
    "        print('Event Triggered...')\n",
    "        triggerEvent = True\n",
    "\n",
    "\n",
    "    return ContourCount, triggerEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countour Bounding Box Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=0\n",
    "s=0\n",
    "\n",
    "def line_removal(image_path):\n",
    "    image = image_path\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (60,1))\n",
    "    verti_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,40))\n",
    "\n",
    "    hori_line = 255-cv2.morphologyEx(image,cv2.MORPH_CLOSE, hori_kernel,iterations=1)\n",
    "\n",
    "    result = cv2.add(image,hori_line)\n",
    "\n",
    "    verti_line = 255 - cv2.morphologyEx(image,cv2.MORPH_CLOSE, verti_kernel,iterations=1)\n",
    "\n",
    "    result = cv2.add(result,verti_line)\n",
    "    return result\n",
    "\n",
    "\n",
    "def word_picker(image):\n",
    "    arr = []\n",
    "    c = 0\n",
    "    out = image.copy()\n",
    "    line_removed = line_removal(image)\n",
    "#     plt.imshow(line_removed)\n",
    "#     plt.show()\n",
    "\n",
    "    imagem = cv2.bitwise_not(line_removed)\n",
    "#     plt.imshow(imagem)\n",
    "#     plt.show()\n",
    "    k = dilation_constant_selector(imagem)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (k,k))\n",
    "    dilate = cv2.dilate(imagem,kernel,iterations=1)\n",
    "#     plt.imshow(dilate)\n",
    "#     plt.show()\n",
    "\n",
    "    contours = cv2.findContours(dilate, \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for i in range(0, len(contours[1])):\n",
    "        area = cv2.contourArea(contours[1][i])\n",
    "        x,y,w,h = cv2.boundingRect(contours[1][i])\n",
    "        #arr.append([x,y,x+w,y+h])\n",
    "        arr.append([x,y,w,h])\n",
    "    cv2.imwrite(\"r.jpg\",out)\n",
    "    arr.sort(key = lambda x: x[2])\n",
    "#     c = random.choice(arr)\n",
    "    print(arr)\n",
    "    print(arr[-1])\n",
    "    c = arr[-1]\n",
    "    crop_img = out[c[1]:c[1]+c[3], c[0]:c[0]+c[2]]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Language Identification and Shape Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = ShapeContext()\n",
    "\n",
    "def get_contour_bounding_rectangles(gray):\n",
    "    \"\"\"\n",
    "      Getting all 2nd level bouding boxes based on contour detection algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    print(gray.shape)\n",
    "    cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    res = []\n",
    "    for cnt in cnts[1]:\n",
    "        (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "        res.append((x, y, x + w, y + h))\n",
    "\n",
    "    return res\n",
    "\n",
    "def parse_nums(sc, path):\n",
    "    global s\n",
    "    img = np.asarray(path)\n",
    "    # invert image colors\n",
    "    img = cv2.bitwise_not(img)\n",
    "    _, img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)\n",
    "    # making numbers fat for better contour detectiion\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "#     print('After thresholding and dilation...')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    # getting our numbers one by one\n",
    "    rois = get_contour_bounding_rectangles(img)\n",
    "    grayd = cv2.cvtColor(img.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    nums = []\n",
    "    for r in rois:\n",
    "        grayd = cv2.rectangle(grayd, (r[0], r[1]), (r[2], r[3]),(0, 255, 0), 1)\n",
    "        nums.append((r[0], r[1], r[2], r[3]))\n",
    "\n",
    "# #     print('After greying and bounding...')\n",
    "    # we are getting contours in different order so we need to sort them by x1\n",
    "    nums = sorted(nums, key=lambda x: x[0])\n",
    "#     print('bounding box x coords')\n",
    "    if (z % 3 == 0):\n",
    "        s = len(nums)\n",
    "    else:\n",
    "        pass\n",
    "    descs = []\n",
    "    for i, r in enumerate(nums):\n",
    "\n",
    "        points = sc.get_points_from_img(img[r[1]:r[3], r[0]:r[2]], 15)\n",
    "        descriptor = sc.compute(points).flatten()\n",
    "        descs.append(descriptor)\n",
    "    #print(descs)\n",
    "    return np.array(descs), s\n",
    "\n",
    "def match(base, current,s):\n",
    "    \"\"\"\n",
    "      Here we are using cosine diff instead of \"by paper\" diff, cause it's faster\n",
    "    \"\"\"\n",
    "    res = cdist(base, current.reshape((1, current.shape[0])), metric=\"cosine\")\n",
    "    # print(\"min = \" + np.argmin(res.reshape(11)))\n",
    "    char = str(np.argmin(res.reshape(s)))\n",
    "    # print(char)\n",
    "#     print(np.min(res.reshape(53)))\n",
    "    return char, np.min(res.reshape(s))\n",
    "\n",
    "\n",
    "def language_identification(language_base,testImg):\n",
    "    d={}\n",
    "    global z,s\n",
    "    matchs=[]\n",
    "    langs=[]\n",
    "    for language,base_url in language_base.items():\n",
    "        print(language,base_url)\n",
    "        baseImage = cv2.imread(base_url,0)\n",
    "        if len(baseImage.shape) !=2:\n",
    "            baseImage=cv2.cvtColor(baseImage, cv2.COLOR_BGR2GRAY)\n",
    "        parsed_base,s = parse_nums(sc, baseImage)\n",
    "        z+=1\n",
    "        recognize,s = parse_nums(sc, testImg)\n",
    "        z+=1\n",
    "        secondImg = cv2.rotate(testImg,cv2.ROTATE_180)\n",
    "        recognize_inverted,s = parse_nums(sc, secondImg)\n",
    "        z+=1\n",
    "        txt = \"\"\n",
    "        matchFactor = 0\n",
    "        val = 0\n",
    "        c=0\n",
    "        for r in recognize:\n",
    "            c, val = match(parsed_base, r,s)\n",
    "            txt += c\n",
    "            matchFactor += val\n",
    "        txtInverted = \"\"\n",
    "        matchFactorInv = 0\n",
    "        val = 0\n",
    "        c=0\n",
    "        for r in recognize_inverted:\n",
    "            c, val = match(parsed_base, r,s)\n",
    "            txtInverted += c\n",
    "            matchFactorInv += val \n",
    "        print(matchFactor,matchFactorInv)\n",
    "#         a = abs(matchFactor-matchFactorInv)\n",
    "#         d[language]=a\n",
    "        matchs.append([matchFactor,matchFactorInv])\n",
    "        langs.append(language)\n",
    "        langs = list(set(langs))\n",
    "    \n",
    "    matc = min(matchs)\n",
    "    index = matchs.index(matc)\n",
    "    language_identified = langs[index]\n",
    "\n",
    "    return language_identified,matc\n",
    "    \n",
    "\n",
    "\n",
    "def findUpright(language_base,testImg):\n",
    "    \n",
    "    language,match1 = language_identification(language_base,testImg)\n",
    "\n",
    "\n",
    "    print(\"\\nUpright Text Match Value = \" + str(match1[0]))\n",
    "    print(\"Flip Text Match Value = \" + str(match1[1]))\n",
    "    \n",
    "    if (match1[0]> match1[1]):\n",
    "        result = \"inverted\"\n",
    "        lang_1 = language\n",
    "        return lang_1, result\n",
    "    else:\n",
    "        result = \"upright\"\n",
    "        lang_1 = language\n",
    "        return lang_1,result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Language Base and Availiable Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.json') as json_file:\n",
    "    language_base = json.load(json_file)\n",
    "    \n",
    "image = cv2.imread(r'./data/8.png',0)\n",
    "cropped = word_picker(image)\n",
    "plt.imshow(cropped)\n",
    "plt.show()\n",
    "language, result = findUpright(language_base,cropped)\n",
    "print(language,result)\n",
    "# match, result = findUpright(cropped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
